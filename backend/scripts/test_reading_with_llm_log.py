#!/usr/bin/env python3
"""
ìƒˆë¡œìš´ ë¦¬ë”©ì„ ìƒì„±í•˜ê³  LLM ë¡œê·¸ê°€ ê¸°ë¡ë˜ëŠ”ì§€ í™•ì¸í•˜ëŠ” í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import asyncio
import sys
import os
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from src.database.factory import get_database_provider


async def check_recent_reading_with_llm_log():
    """ê°€ì¥ ìµœê·¼ ë¦¬ë”©ì˜ LLM ë¡œê·¸ í™•ì¸"""
    provider = get_database_provider()

    # Get the most recent reading
    readings_list = provider.db.collection('readings').order_by('created_at', direction='DESCENDING').limit(1).get()

    if not readings_list:
        print("âŒ ë¦¬ë”©ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    doc = list(readings_list)[0]
    data = doc.to_dict()

    print('=' * 80)
    print(f'ìµœê·¼ ë¦¬ë”© í™•ì¸: {doc.id}')
    print('=' * 80)
    print(f'Question: {data.get("question")}')
    print(f'Spread Type: {data.get("spread_type")}')
    print(f'Created At: {data.get("created_at")}')
    print(f'Summary: {data.get("summary", "")[:100]}...')

    # Check LLM usage
    llm_usage = data.get('llm_usage', [])

    if llm_usage:
        print(f'\nâœ… LLM Usage ë¡œê·¸ ë°œê²¬! ({len(llm_usage)}ê°œ)')
        print('=' * 80)

        total_cost = sum(log.get('estimated_cost', 0) for log in llm_usage)
        total_tokens = sum(log.get('total_tokens', 0) for log in llm_usage)

        print(f'\nğŸ“Š ì „ì²´ ìš”ì•½:')
        print(f'   ì‹œë„ íšŸìˆ˜: {len(llm_usage)}')
        print(f'   ì´ í† í°: {total_tokens:,}')
        print(f'   ì´ ë¹„ìš©: ${total_cost:.6f}')

        print(f'\nğŸ“ ìƒì„¸ ë¡œê·¸:')
        for idx, log in enumerate(llm_usage, 1):
            print(f'\n   [{idx}] {log.get("purpose", "unknown").upper()}')
            print(f'       Provider: {log.get("provider")}')
            print(f'       Model: {log.get("model")}')
            print(f'       Prompt Tokens: {log.get("prompt_tokens", 0):,}')
            print(f'       Completion Tokens: {log.get("completion_tokens", 0):,}')
            print(f'       Total Tokens: {log.get("total_tokens", 0):,}')
            print(f'       Cost: ${log.get("estimated_cost", 0):.6f}')
            print(f'       Latency: {log.get("latency_seconds", 0):.2f}s')
            print(f'       Created At: {log.get("created_at")}')
    else:
        print(f'\nâŒ LLM Usage ë¡œê·¸ ì—†ìŒ')
        print('\nğŸ’¡ ì´ ë¦¬ë”©ì€ LLM ë¡œê·¸ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ê¸° ì „ì— ìƒì„±ëœ ê²ƒ ê°™ìŠµë‹ˆë‹¤.')
        print('   ìƒˆë¡œìš´ ë¦¬ë”©ì„ ìƒì„±í•˜ë©´ LLM ë¡œê·¸ê°€ ê¸°ë¡ë©ë‹ˆë‹¤.')


if __name__ == "__main__":
    asyncio.run(check_recent_reading_with_llm_log())
